\begin{section}{Discusión}
	En esta sección, buscaremos conclusiones a la información suministrada por los gráficos de la sección anterior.\\
	
	El primer gráfico presenta la calidad de las matrices mal condicionadas en función de su dimensión generadas a 
	partir de un epsilon dado (Figura:\ref{fig:epsilon}).
	
	Observamos que a medida que fijamos un $epsilon$ menor, obtenemos una matriz con un número de condición mayor. 
	Más aun, el disminuir un orden de magnitud al $epsilon$ implica un aumento en un orden de magnitud en el número
	 de condición de la matriz.
	
	Este gráfico dio sustento a nuestra hipotesis presentada anteriormente (a menor $epsilon$ mayor número de 
	condición).
	
	A partir del gráfico podemos decir también que cuanto mayor sea la dimensión de la  matriz peor condicionada 
	estará (al menos construyéndolas de esta manera) ya que los valores obtenidos (número de condición) en función 
	de la dimensión de la matiz, fijando un $epsilon$, forman una curva logarítmica. Como el gráfico se encuentra 
	bajo una escala logarítmica el número de condición de la matriz crece linealmente conforme aumenta su dimensión.
	
	Teniendo en cuenta los resultados aquí expuestos y considerando las restricciones impuestas en el valor de 
	$epsilon$ (ver sección \texttt{Resultados}) decidimos que $1e^{-6}$ es el valor adecuado.\pa
	
	Analizando el segundo gráfico (Figura:\ref{fig:inv_vs_lu}), vemos que la implementación utilizando el algoritmo de factorización LU conseguimos soluciones más aproximadas a la exacta. Existe mayor propagación de errores en el cálculo de la inversa mediante el método de Gauss. Suponemos que esta diferencia es proporcional a la cantidad de cálculos y al tipo de matrices utilizadas para resolver el sistema. Cada una de las matrices que se obtienen mediante la factorización LU (es decir la L, y la U), poseen a lo sumo la mitad de elementos no nulos y la diagonal. Cuando estas matrices se multiplican por el vector correspondiente (sustitución reversa y sustitución hacia adelante), al ser triangulares, existe menor propagación de errores que al multiplicar la inversa por el vector.
	
	A partir del gráfico suponemos que resolver un sistema mediante el método de la inversa implica mayor cantidad de operaciones y/u operaciones que propagan errores más grandes que resolverlo por el método de factorización LU.\pa
		
	El último gráfico adjuntado, (Figura:\ref{fig:prom_vs_direct}) refuta nuestra hipótesis, es decir, demuestra que nuestra estrategia de ir aproximándonos al enemigo mediante el promedio de las posiciones calculadas hasta el momento no resuelve como lo esperabamos. Tomar el promedio mejora la solución muy lentamente, en $500$ turnos logramos refinar la puntería en aproximadamente un orden de magnitud, refinamiento que no nos sirve ya que la distancia de la posición calculada por nosotros a la posición real del enemigo es de varios órdenes de magnitud y la batalla dura unos pocos turnos.
	
	Tomar el promedio estabiliza la precisión del disparo y se acerca progresivamente al enemigo siempre y cuando los datos no sean muy dispersos, es decir, si el error cometido en estos disparos es muy variable el promedio se torna en una herramienta no tan eficaz. Esto nos lleva a pensar en la conveniencia de disparar directamente, ya que existe mayor probabilidad que utilizando sólo la información del disparo nos acerquemos más que promediando datos que nos alejan de la misma. Surge entonces el problema que si la matriz es de dimensión grande y mal condicionada, el error cometido sería suficiente para que nunca diéramos con el oponente.
	
	Este gráfico nos lleva a pensar en dos posibilidades, o tenemos un mal algoritmo para la resolución de sistemas de ecuaciones o no tenemos una buena estrategia para hallar al enemigo a partir de los datos disponibles.\\

	\underline{NOTA:} Se utilizó factorización LU para la resolución del sistema de ecuaciones lineales porque vimos en (Figura:\ref{fig:inv_vs_lu}) que es más preciso en comparación a la otra opción disponible (Inversa). 

\end{section}
