\begin{section}{Introducción teórica}	
	Multitud de problemas de la vida real se rigen por proporciones constantes entre las magnitudes implicadas: procesos físicos, reacciones químicas, costes de materias primas y sus relaciones para formar otros producto, etc.
	Todas estas situaciones admiten de forma natural una descripción matemática a través de sistemas de ecuaciones lineales.
	Además estos sistemas son útiles como una buena aproximación a sistemas más complejos o sistemas de ecuaciones no-lineales.
	
	La resolución de muchos problemas conlleva el manejo de grandes sistemas de ecuaciones lineales, por lo que es necesario plantearse métodos eficientes para su análisis.
	
	Los sistemas de ecuaciones lineales son un conjunto de $m$ ecuaciones relacionadas en $n$ variables. Se los puede expresar en forma matricial como $A \dot x = b$ donde $A$ es una matriz de $m \times n$, $x$ es un vector columna de tamaño $n$ y $b$ un vector de tamaño $m$.
	
	Existen diversos métodos para la resolución de estos sistemas de ecuaciones. Haremos una breve introducción a los distintos métodos.
	
	Tenemos por un lado los métodos iterativos como es el caso del método de Jacobi, Gauss-Seidel o del Gradiente Conjugado que como su nombre lo indica se los aplica en forma iterativa para lograr una aproximación a la solución real del sistema en cuestión
	
	Por otra parte, existen los denominados métodos directos entre los cuales se encuentra el método de eliminación de Gauss el cual es una forma directa para llegar en un número finito de pasos a un sistema equivalente pero más simple, la factorización LU que se vale de este último, la descomposición de Cholesky, y la descomposición QR.	\footnote{Burden y J.D.Faires, Análisis numérico, International Thomson Editors, 1998}
\end{section}
